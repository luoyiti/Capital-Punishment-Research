{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "764fd55e1f5758a8"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {},
   "source": [
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0'\n",
    "}\n",
    "base_url = \"https://www.tdcj.texas.gov\"\n",
    "list_url = f\"{base_url}/death_row/dr_executed_offenders.html\"\n",
    "\n",
    "# 1. 获取所有详情页链接\n",
    "response = requests.get(list_url, headers=headers, timeout=1000, verify=False)\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "links = []\n",
    "\n",
    "table_rows = soup.select(\"table tr\")[1:]  # 跳过表头\n",
    "# 示例：https://www.tdcj.texas.gov/death_row/dr_info/mullistravis.html\n",
    "for row in table_rows:\n",
    "    link_tag = row.find_all(\"td\")[1].find(\"a\")  # 第二列\n",
    "    if link_tag and \"href\" in link_tag.attrs:\n",
    "        href = link_tag['href']\n",
    "        full_link = base_url + \"/death_row/\" + href\n",
    "        links.append(full_link)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d0a43f353b433a19",
   "metadata": {},
   "source": "links",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bbdf6f743076c377",
   "metadata": {},
   "source": [
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "\n",
    "def create_session_with_retries(retries=30, backoff_factor=0.3, status_forcelist=(500, 502, 503, 504)):\n",
    "    session = requests.Session()\n",
    "    retry = Retry(\n",
    "        total=retries,\n",
    "        read=retries,\n",
    "        connect=retries,\n",
    "        backoff_factor=backoff_factor,\n",
    "        status_forcelist=status_forcelist,\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount(\"http://\", adapter)\n",
    "    session.mount(\"https://\", adapter)\n",
    "    return session\n",
    "\n",
    "session = create_session_with_retries()\n",
    "\n",
    "def extract_info(url):\n",
    "    try:\n",
    "        r = session.get(url, headers=headers, timeout=10, verify=False)  # 禁用 SSL 验证\n",
    "        s = BeautifulSoup(r.content, \"html.parser\")\n",
    "        text = s.get_text(separator=\"\\n\")\n",
    "\n",
    "        return {\n",
    "            \"URL\": url,\n",
    "            \"text\": text\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"错误处理 {url} ：{e}\")\n",
    "        return None\n",
    "\n",
    "# 3. 批量爬取并保存\n",
    "results = []\n",
    "for i, url in enumerate(links):\n",
    "    print(f\"正在处理第 {i+1}/{len(links)} 个: {url}\")\n",
    "    data = extract_info(url)\n",
    "    if data:\n",
    "        results.append(data)\n",
    "    time.sleep(1)\n",
    "\n",
    "# 4. 保存为 CSV\n",
    "with open(\"tdcj_on_death_row.csv\", \"w\", newline='', encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=results[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(results)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "not_found = []\n",
    "for i in results:\n",
    "    if '.jpg' in i['URL']:\n",
    "        not_found.append(i)\n",
    "    else:\n",
    "        if 'Error 404' in i['text']:\n",
    "            not_found.append(i)\n",
    "not_found"
   ],
   "id": "6da569018ad17147",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "not_found_urls = [item['URL'] for item in not_found]\n",
    "finresults = [item for item in results if item['URL'] not in not_found_urls]\n",
    "finresults"
   ],
   "id": "977c30ee0bbd492d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(not)",
   "id": "599b7063b705c054",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "def parse_death_row_info(text):\n",
    "    \"\"\"\n",
    "    Parses the death row information from the provided text and returns a dictionary of key fields.\n",
    "\n",
    "    Args:\n",
    "        text (str): The raw text containing death row information.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the parsed fields.\n",
    "    \"\"\"\n",
    "    fields = {\n",
    "        \"Name\": re.search(r\"Name\\s+([\\w, ]+)\", text),\n",
    "        \"TDCJ Number\": re.search(r\"TDCJ Number\\s+(\\d+)\", text),\n",
    "        \"Date of Birth\": re.search(r\"Date of Birth\\s+([\\d/]+)\", text),\n",
    "        \"Date Received\": re.search(r\"Date Received\\s+([\\d/]+)\", text),\n",
    "        \"Education Level\": re.search(r\"Education Level \\(Highest Grade Completed\\)\\s+(\\d+)\", text),\n",
    "        \"Date of Offense\": re.search(r\"Date of Offense\\s+([\\d/]+)\", text),\n",
    "        \"County\": re.search(r\"County\\s+([\\w ]+)\", text),\n",
    "        \"Race\": re.search(r\"Race\\s+(\\w+)\", text),\n",
    "        \"Gender\": re.search(r\"Gender\\s+(\\w+)\", text),\n",
    "        \"Height\": re.search(r\"Height \\(in Feet and Inches\\)\\s+([\\d′″ ]+)\", text),\n",
    "        \"Weight\": re.search(r\"Weight \\(in Pounds\\)\\s+(\\d+)\", text),\n",
    "        \"Eye Color\": re.search(r\"Eye Color\\s+([\\w ]+)\", text),\n",
    "        \"Summary of Incident\": re.search(r\"Summary of Incident\\s+([\\s\\S]+?)(?=Co-Defendants|Race and Gender of Victim)\", text),\n",
    "        \"Co-Defendants\": re.search(r\"Co-Defendants\\s+([\\w ]+)\", text),\n",
    "        \"Race and Gender of Victim\": re.search(r\"Race and Gender of Victim\\s+([\\w ]+)\", text),\n",
    "    }\n",
    "\n",
    "    # Extract matched groups and return as a dictionary\n",
    "    return {key: match.group(1).strip() if match else None for key, match in fields.items()}"
   ],
   "id": "416fbb80e504bfdf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "new_dict = {}\n",
    "for i in finresults:\n",
    "    new_dict[i['URL']] = parse_death_row_info(i['text'])\n",
    "new_dict"
   ],
   "id": "2748c3db5ff5bd73",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 将嵌套字典转换为记录列表\n",
    "records = []\n",
    "for url, info in new_dict.items():\n",
    "    record = info.copy()  # 复制信息字典\n",
    "    record['URL'] = url   # 添加URL字段\n",
    "    records.append(record)\n",
    "\n",
    "# 使用pandas保存为CSV\n",
    "df = pd.DataFrame(records)\n",
    "df.to_csv(\"death_row_lastwords_more_info.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"已成功保存{len(records)}条死刑犯信息记录到death_row_inmates_info.csv文件\")"
   ],
   "id": "ba3fb67746b29294",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open('not_found_urls.txt', 'w') as f:\n",
    "    for url in not_found_urls:\n",
    "        f.write(url + '\\n')"
   ],
   "id": "80a63b6d7d745449",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fecf8d7f9dea0ee4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
