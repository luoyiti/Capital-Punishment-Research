{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T02:48:04.374524Z",
     "start_time": "2025-05-08T02:48:04.368636Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5de0a4b54fda0d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52993464",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_text = \"I would like to apologize to the Nix family for taking Mark away from you. I hope this brings you closure. I want to say to all my family and friends around the world 'thank you' for supporting me. To my kids, stand tall and continue to make me proud. Don¡¯t worry about me, I'm ready to fly. Alright Warden, I¡¯m ready to ride.\"\n",
    "doc = nlp(trial_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7100caf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I: PRON, nsubj\n",
      "would: AUX, aux\n",
      "like: VERB, ROOT\n",
      "to: PART, aux\n",
      "apologize: VERB, xcomp\n",
      "to: ADP, prep\n",
      "the: DET, det\n",
      "Nix: PROPN, compound\n",
      "family: NOUN, pobj\n",
      "for: ADP, prep\n",
      "taking: VERB, pcomp\n",
      "Mark: PROPN, dobj\n",
      "away: ADV, advmod\n",
      "from: ADP, prep\n",
      "you: PRON, pobj\n",
      ".: PUNCT, punct\n",
      "I: PRON, nsubj\n",
      "hope: VERB, ROOT\n",
      "this: PRON, nsubj\n",
      "brings: VERB, ccomp\n",
      "you: PRON, dative\n",
      "closure: NOUN, dobj\n",
      ".: PUNCT, punct\n",
      "I: PRON, nsubj\n",
      "want: VERB, ROOT\n",
      "to: PART, aux\n",
      "say: VERB, xcomp\n",
      "to: ADP, prep\n",
      "all: DET, det\n",
      "my: PRON, poss\n",
      "family: NOUN, pobj\n",
      "and: CCONJ, cc\n",
      "friends: NOUN, conj\n",
      "around: ADP, prep\n",
      "the: DET, det\n",
      "world: NOUN, pobj\n",
      "': PUNCT, punct\n",
      "thank: VERB, ccomp\n",
      "you: PRON, dobj\n",
      "': PUNCT, punct\n",
      "for: ADP, prep\n",
      "supporting: VERB, pcomp\n",
      "me: PRON, dobj\n",
      ".: PUNCT, punct\n",
      "To: ADP, prep\n",
      "my: PRON, poss\n",
      "kids: NOUN, pobj\n",
      ",: PUNCT, punct\n",
      "stand: VERB, ROOT\n",
      "tall: ADJ, advmod\n",
      "and: CCONJ, cc\n",
      "continue: VERB, conj\n",
      "to: PART, aux\n",
      "make: VERB, xcomp\n",
      "me: PRON, nsubj\n",
      "proud: ADJ, ccomp\n",
      ".: PUNCT, punct\n",
      "Don¡¯t: NOUN, nsubj\n",
      "worry: VERB, ccomp\n",
      "about: ADP, prep\n",
      "me: PRON, pobj\n",
      ",: PUNCT, punct\n",
      "I: PRON, nsubj\n",
      "'m: AUX, ROOT\n",
      "ready: ADJ, acomp\n",
      "to: PART, aux\n",
      "fly: VERB, xcomp\n",
      ".: PUNCT, punct\n",
      "Alright: PROPN, compound\n",
      "Warden: PROPN, nsubj\n",
      ",: PUNCT, punct\n",
      "I¡¯m: VERB, ROOT\n",
      "ready: ADJ, acomp\n",
      "to: PART, aux\n",
      "ride: VERB, xcomp\n",
      ".: PUNCT, punct\n"
     ]
    }
   ],
   "source": [
    "# 识别语法角色及句子结构关系\n",
    "for token in doc:\n",
    "      print(f\"{token.text}: {token.pos_}, {token.dep_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee62f45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nix - PERSON\n",
      "Mark - PERSON\n",
      "I¡¯m - GPE\n"
     ]
    }
   ],
   "source": [
    "# 识别命名实体\n",
    "for ent in doc.ents:\n",
    "      print(f\"{ent.text} - {ent.label_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd241ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I would like to apologize to the Nix family for taking Mark away from you.\n",
      "I hope this brings you closure.\n",
      "I want to say to all my family and friends around the world 'thank you' for supporting me.\n",
      "To my kids, stand tall and continue to make me proud.\n",
      "Don¡¯t worry about me, I'm ready to fly.\n",
      "Alright Warden, I¡¯m ready to ride.\n"
     ]
    }
   ],
   "source": [
    "# 识别句子\n",
    "assert doc.has_annotation(\"SENT_START\")\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "497c4a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I ← 头词: like\n",
      "would ← 头词: like\n",
      "like ← 头词: like\n",
      "to ← 头词: apologize\n",
      "apologize ← 头词: like\n",
      "to ← 头词: apologize\n",
      "the ← 头词: family\n",
      "Nix ← 头词: family\n",
      "family ← 头词: to\n",
      "for ← 头词: apologize\n",
      "taking ← 头词: for\n",
      "Mark ← 头词: taking\n",
      "away ← 头词: taking\n",
      "from ← 头词: away\n",
      "you ← 头词: from\n",
      ". ← 头词: like\n",
      "I ← 头词: hope\n",
      "hope ← 头词: hope\n",
      "this ← 头词: brings\n",
      "brings ← 头词: hope\n",
      "you ← 头词: brings\n",
      "closure ← 头词: brings\n",
      ". ← 头词: hope\n",
      "I ← 头词: want\n",
      "want ← 头词: want\n",
      "to ← 头词: say\n",
      "say ← 头词: want\n",
      "to ← 头词: say\n",
      "all ← 头词: family\n",
      "my ← 头词: family\n",
      "family ← 头词: to\n",
      "and ← 头词: family\n",
      "friends ← 头词: family\n",
      "around ← 头词: family\n",
      "the ← 头词: world\n",
      "world ← 头词: around\n",
      "' ← 头词: say\n",
      "thank ← 头词: say\n",
      "you ← 头词: thank\n",
      "' ← 头词: thank\n",
      "for ← 头词: thank\n",
      "supporting ← 头词: for\n",
      "me ← 头词: supporting\n",
      ". ← 头词: want\n",
      "To ← 头词: stand\n",
      "my ← 头词: kids\n",
      "kids ← 头词: To\n",
      ", ← 头词: stand\n",
      "stand ← 头词: stand\n",
      "tall ← 头词: stand\n",
      "and ← 头词: stand\n",
      "continue ← 头词: stand\n",
      "to ← 头词: make\n",
      "make ← 头词: continue\n",
      "me ← 头词: proud\n",
      "proud ← 头词: make\n",
      ". ← 头词: stand\n",
      "Don¡¯t ← 头词: worry\n",
      "worry ← 头词: 'm\n",
      "about ← 头词: worry\n",
      "me ← 头词: about\n",
      ", ← 头词: 'm\n",
      "I ← 头词: 'm\n",
      "'m ← 头词: 'm\n",
      "ready ← 头词: 'm\n",
      "to ← 头词: fly\n",
      "fly ← 头词: ready\n",
      ". ← 头词: 'm\n",
      "Alright ← 头词: Warden\n",
      "Warden ← 头词: I¡¯m\n",
      ", ← 头词: Warden\n",
      "I¡¯m ← 头词: I¡¯m\n",
      "ready ← 头词: I¡¯m\n",
      "to ← 头词: ride\n",
      "ride ← 头词: ready\n",
      ". ← 头词: I¡¯m\n"
     ]
    }
   ],
   "source": [
    "# 分析句法树\n",
    "for token in doc:\n",
    "    print(f\"{token.text} ← 头词: {token.head.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "deb6de29",
   "metadata": {},
   "outputs": [],
   "source": [
    "appologize_tokens = [\n",
    "    'sorry',\n",
    "    'apologize',\n",
    "    'forgive',\n",
    "    'regret',\n",
    "    'remorse',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23faa560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I: False\n",
      "would: False\n",
      "like: False\n",
      "to: False\n",
      "apologize: True\n",
      "to: False\n",
      "the: False\n",
      "Nix: False\n",
      "family: False\n",
      "for: False\n",
      "taking: False\n",
      "Mark: False\n",
      "away: False\n",
      "from: False\n",
      "you: False\n",
      ".: False\n",
      "I: False\n",
      "hope: False\n",
      "this: False\n",
      "brings: False\n",
      "you: False\n",
      "closure: False\n",
      ".: False\n",
      "I: False\n",
      "want: False\n",
      "to: False\n",
      "say: False\n",
      "to: False\n",
      "all: False\n",
      "my: False\n",
      "family: False\n",
      "and: False\n",
      "friends: False\n",
      "around: False\n",
      "the: False\n",
      "world: False\n",
      "': False\n",
      "thank: False\n",
      "you: False\n",
      "': False\n",
      "for: False\n",
      "supporting: False\n",
      "me: False\n",
      ".: False\n",
      "To: False\n",
      "my: False\n",
      "kids: False\n",
      ",: False\n",
      "stand: False\n",
      "tall: False\n",
      "and: False\n",
      "continue: False\n",
      "to: False\n",
      "make: False\n",
      "me: False\n",
      "proud: False\n",
      ".: False\n",
      "Don¡¯t: False\n",
      "worry: False\n",
      "about: False\n",
      "me: False\n",
      ",: False\n",
      "I: False\n",
      "'m: False\n",
      "ready: False\n",
      "to: False\n",
      "fly: False\n",
      ".: False\n",
      "Alright: False\n",
      "Warden: False\n",
      ",: False\n",
      "I¡¯m: False\n",
      "ready: False\n",
      "to: False\n",
      "ride: False\n",
      ".: False\n"
     ]
    }
   ],
   "source": [
    "# 添加自定义属性\n",
    "from spacy.tokens import Token\n",
    "#Token.set_extension(\"is_apology\", default=False)\n",
    "# 为含有道歉词汇的token设置标记\n",
    "for token in doc:\n",
    "    if token.text.lower() in [\"apologize\", \"sorry\"]:\n",
    "        token._.is_apology = True\n",
    "    print(f\"{token.text}: {token._.is_apology}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
